% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/data_types.R
\name{array_type}
\alias{array_type}
\alias{binary_type}
\alias{boolean_type}
\alias{byte_type}
\alias{calendar_interval_type}
\alias{char_type}
\alias{date_type}
\alias{double_type}
\alias{float_type}
\alias{integer_type}
\alias{long_type}
\alias{map_type}
\alias{null_type}
\alias{short_type}
\alias{string_type}
\alias{struct_field}
\alias{struct_type}
\alias{timestamp_type}
\alias{varchar_type}
\title{Spark Data Types}
\usage{
array_type(sc, data_type, nullable = FALSE)

binary_type(sc)

boolean_type(sc)

byte_type(sc)

calendar_interval_type(sc)

char_type(sc, length)

date_type(sc)

double_type(sc)

float_type(sc)

integer_type(sc)

long_type(sc)

map_type(sc, key_type, value_type, nullable = FALSE)

null_type(sc)

short_type(sc)

string_type(sc)

struct_field(sc, name, data_type, nullable = FALSE)

struct_type(sc, struct_fields)

timestamp_type(sc)

varchar_type(sc, length)
}
\description{
These function support supplying a spark read schema. This is particularly useful
when reading data with nested arrays when you are not interested in several of 
the nested fields.
}
